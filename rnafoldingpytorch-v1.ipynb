{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":87793,"databundleVersionId":11553390,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stanford RNA 3D Folding\n- *notify  :  The work is based on **PyTorch**. As a beginner participating in this competition,its my great honor to have ur comments and encouragement. Criticism and corrections are also welcome.*\n- *Author  :  **Chengzhi Jiang***","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:00.799901Z","iopub.execute_input":"2025-04-01T12:08:00.800179Z","iopub.status.idle":"2025-04-01T12:08:01.707037Z","shell.execute_reply.started":"2025-04-01T12:08:00.800150Z","shell.execute_reply":"2025-04-01T12:08:01.706138Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Dataset Overview","metadata":{}},{"cell_type":"code","source":"train_labels = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/train_labels.csv\")\ntrain_sequence = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/train_sequences.csv\")\nval_labels = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/validation_labels.csv\")\nval_sequence = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/validation_sequences.csv\")\ntest_sequence = pd.read_csv(\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\")\n\nprint(\"Train Seq: \" + str(train_sequence.shape))\nprint(\"Train Label: \" + str(train_labels.shape))\nprint(\"Validation Seq: \" + str(val_sequence.shape))\nprint(\"Validation Label: \" + str(val_labels.shape))\nprint(\"Test: \"+str(test_sequence.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:03.179800Z","iopub.execute_input":"2025-04-01T12:08:03.180104Z","iopub.status.idle":"2025-04-01T12:08:03.624908Z","shell.execute_reply.started":"2025-04-01T12:08:03.180075Z","shell.execute_reply":"2025-04-01T12:08:03.624103Z"}},"outputs":[{"name":"stdout","text":"Train Seq: (844, 5)\nTrain Label: (137095, 6)\nValidation Seq: (12, 5)\nValidation Label: (2515, 123)\nTest: (12, 5)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:05.261647Z","iopub.execute_input":"2025-04-01T12:08:05.261941Z","iopub.status.idle":"2025-04-01T12:08:05.286850Z","shell.execute_reply.started":"2025-04-01T12:08:05.261918Z","shell.execute_reply":"2025-04-01T12:08:05.286183Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         ID resname  resid     x_1        y_1     z_1\n0  1SCL_A_1       G      1  13.760 -25.974001   0.102\n1  1SCL_A_2       G      2   9.310 -29.638000   2.669\n2  1SCL_A_3       G      3   5.529 -27.813000   5.878\n3  1SCL_A_4       U      4   2.678 -24.900999   9.793\n4  1SCL_A_5       G      5   1.827 -20.136000  11.793","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>resname</th>\n      <th>resid</th>\n      <th>x_1</th>\n      <th>y_1</th>\n      <th>z_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1SCL_A_1</td>\n      <td>G</td>\n      <td>1</td>\n      <td>13.760</td>\n      <td>-25.974001</td>\n      <td>0.102</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1SCL_A_2</td>\n      <td>G</td>\n      <td>2</td>\n      <td>9.310</td>\n      <td>-29.638000</td>\n      <td>2.669</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1SCL_A_3</td>\n      <td>G</td>\n      <td>3</td>\n      <td>5.529</td>\n      <td>-27.813000</td>\n      <td>5.878</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1SCL_A_4</td>\n      <td>U</td>\n      <td>4</td>\n      <td>2.678</td>\n      <td>-24.900999</td>\n      <td>9.793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1SCL_A_5</td>\n      <td>G</td>\n      <td>5</td>\n      <td>1.827</td>\n      <td>-20.136000</td>\n      <td>11.793</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train_sequence.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:05.952466Z","iopub.execute_input":"2025-04-01T12:08:05.952705Z","iopub.status.idle":"2025-04-01T12:08:05.961085Z","shell.execute_reply.started":"2025-04-01T12:08:05.952684Z","shell.execute_reply":"2025-04-01T12:08:05.960287Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  target_id                            sequence temporal_cutoff  \\\n0    1SCL_A       GGGUGCUCAGUACGAGAGGAACCGCACCC      1995-01-26   \n1    1RNK_A  GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU      1995-02-27   \n2    1RHT_A            GGGACUGACGAUCACGCAGUCUAU      1995-06-03   \n3    1HLX_A                GGGAUAACUUCGGUUGUCCC      1995-09-15   \n4    1HMH_E  GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU      1995-12-07   \n\n                                         description  \\\n0               THE SARCIN-RICIN LOOP, A MODULAR RNA   \n1  THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...   \n2  24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...   \n3  P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID   \n4  THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...   \n\n                                       all_sequences  \n0  >1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...  \n1  >1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...  \n2  >1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...  \n3  >1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...  \n4  >1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_id</th>\n      <th>sequence</th>\n      <th>temporal_cutoff</th>\n      <th>description</th>\n      <th>all_sequences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1SCL_A</td>\n      <td>GGGUGCUCAGUACGAGAGGAACCGCACCC</td>\n      <td>1995-01-26</td>\n      <td>THE SARCIN-RICIN LOOP, A MODULAR RNA</td>\n      <td>&gt;1SCL_1|Chain A|RNA SARCIN-RICIN LOOP|Rattus n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1RNK_A</td>\n      <td>GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU</td>\n      <td>1995-02-27</td>\n      <td>THE STRUCTURE OF AN RNA PSEUDOKNOT THAT CAUSES...</td>\n      <td>&gt;1RNK_1|Chain A|RNA PSEUDOKNOT|null\\nGGCGCAGUG...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1RHT_A</td>\n      <td>GGGACUGACGAUCACGCAGUCUAU</td>\n      <td>1995-06-03</td>\n      <td>24-MER RNA HAIRPIN COAT PROTEIN BINDING SITE F...</td>\n      <td>&gt;1RHT_1|Chain A|RNA (5'-R(P*GP*GP*GP*AP*CP*UP*...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1HLX_A</td>\n      <td>GGGAUAACUUCGGUUGUCCC</td>\n      <td>1995-09-15</td>\n      <td>P1 HELIX NUCLEIC ACIDS (DNA/RNA) RIBONUCLEIC ACID</td>\n      <td>&gt;1HLX_1|Chain A|RNA (5'-R(*GP*GP*GP*AP*UP*AP*A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1HMH_E</td>\n      <td>GGCGACCCUGAUGAGGCCGAAAGGCCGAAACCGU</td>\n      <td>1995-12-07</td>\n      <td>THREE-DIMENSIONAL STRUCTURE OF A HAMMERHEAD RI...</td>\n      <td>&gt;1HMH_1|Chains A, C, E|HAMMERHEAD RIBOZYME-RNA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"val_labels.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:06.543196Z","iopub.execute_input":"2025-04-01T12:08:06.543498Z","iopub.status.idle":"2025-04-01T12:08:06.569322Z","shell.execute_reply.started":"2025-04-01T12:08:06.543473Z","shell.execute_reply":"2025-04-01T12:08:06.568637Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        ID resname  resid    x_1        y_1        z_1           x_2  \\\n0  R1107_1       G      1 -5.499   8.520000   8.605000 -1.000000e+18   \n1  R1107_2       G      2 -5.826  10.453000  14.010000 -1.000000e+18   \n2  R1107_3       G      3 -5.849  14.768000  17.584999 -1.000000e+18   \n3  R1107_4       G      4 -5.784  19.985001  18.666000 -1.000000e+18   \n4  R1107_5       G      5 -5.755  25.533001  17.132999 -1.000000e+18   \n\n            y_2           z_2           x_3  ...          z_37          x_38  \\\n0 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n1 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n2 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n3 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n4 -1.000000e+18 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18   \n\n           y_38          z_38          x_39          y_39          z_39  \\\n0 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n1 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n2 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n3 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n4 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18 -1.000000e+18   \n\n           x_40          y_40          z_40  \n0 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n1 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n2 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n3 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n4 -1.000000e+18 -1.000000e+18 -1.000000e+18  \n\n[5 rows x 123 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>resname</th>\n      <th>resid</th>\n      <th>x_1</th>\n      <th>y_1</th>\n      <th>z_1</th>\n      <th>x_2</th>\n      <th>y_2</th>\n      <th>z_2</th>\n      <th>x_3</th>\n      <th>...</th>\n      <th>z_37</th>\n      <th>x_38</th>\n      <th>y_38</th>\n      <th>z_38</th>\n      <th>x_39</th>\n      <th>y_39</th>\n      <th>z_39</th>\n      <th>x_40</th>\n      <th>y_40</th>\n      <th>z_40</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>R1107_1</td>\n      <td>G</td>\n      <td>1</td>\n      <td>-5.499</td>\n      <td>8.520000</td>\n      <td>8.605000</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>...</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>R1107_2</td>\n      <td>G</td>\n      <td>2</td>\n      <td>-5.826</td>\n      <td>10.453000</td>\n      <td>14.010000</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>...</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>R1107_3</td>\n      <td>G</td>\n      <td>3</td>\n      <td>-5.849</td>\n      <td>14.768000</td>\n      <td>17.584999</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>...</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>R1107_4</td>\n      <td>G</td>\n      <td>4</td>\n      <td>-5.784</td>\n      <td>19.985001</td>\n      <td>18.666000</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>...</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>R1107_5</td>\n      <td>G</td>\n      <td>5</td>\n      <td>-5.755</td>\n      <td>25.533001</td>\n      <td>17.132999</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>...</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n      <td>-1.000000e+18</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 123 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"seq_dict = {'A': 1, 'C': 2, 'G': 3, 'U': 4}\ndef seq_map(seq):\n    return [seq_dict.get(char, 0) for char in seq]\n\ntrain_sequence['encoded_seq'] = train_sequence['sequence'].apply(seq_map)\ntest_sequence['encoded_seq'] = test_sequence['sequence'].apply(seq_map)\nval_sequence['encoded_seq'] = val_sequence['sequence'].apply(seq_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:08.599525Z","iopub.execute_input":"2025-04-01T12:08:08.599812Z","iopub.status.idle":"2025-04-01T12:08:08.619436Z","shell.execute_reply.started":"2025-04-01T12:08:08.599788Z","shell.execute_reply":"2025-04-01T12:08:08.618667Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from collections import defaultdict\n\ndef generate_label_coord(frame):\n    output = defaultdict(list)\n\n    frame['label'] = frame.ID.str.rsplit('_', n=1, expand=True).iloc[:, 0] #将frame中label中的内容修改下,从右边开始去掉一次\n\n    for _, row in frame.iterrows():\n        label = row['label']\n        resid = row['resid']     #residual id 残基序号(索引)  每个核苷酸的位置由5'端 -> 3'端 一次编号\n\n        coord = np.array((row['x_1'], row['y_1'], row['z_1']), dtype=np.float32)\n        output[label].append((resid, coord))\n\n    for key, value in output.items():  #这里如果不用item() 只能遍历key\n        coords = np.stack([c for r, c in value])\n        masks = np.isnan(coords) | np.isclose(coords, -1.0000e+18)  #接近阈值为True:-1.0000e+18 \n\n        coords[masks] = 0.  #无效坐标位置置0\n\n        output[key] = {\n            'coords': coords, #得到修正后的坐标矩阵\n            'masks': ~masks,  #标记有效坐标\n        }\n\n    return output\n\ntrain_stacked_coords = generate_label_coord(train_labels)\nval_stacked_coords = generate_label_coord(val_labels)\n\ntrain_stacked_coords[list(train_stacked_coords.keys())[0]]  #获取list中第一个key的对应coords坐标信息以及mask掩码矩阵","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:09.915971Z","iopub.execute_input":"2025-04-01T12:08:09.916250Z","iopub.status.idle":"2025-04-01T12:08:17.524550Z","shell.execute_reply.started":"2025-04-01T12:08:09.916228Z","shell.execute_reply":"2025-04-01T12:08:17.523764Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'coords': array([[ 13.76 , -25.974,   0.102],\n        [  9.31 , -29.638,   2.669],\n        [  5.529, -27.813,   5.878],\n        [  2.678, -24.901,   9.793],\n        [  1.827, -20.136,  11.793],\n        [  2.04 , -14.908,  11.771],\n        [  1.107, -11.513,   7.517],\n        [  2.991,  -6.406,   4.783],\n        [  0.896,  -1.193,   7.608],\n        [  0.228,   2.646,   9.128],\n        [  4.329,   2.718,   4.804],\n        [  5.165,   4.792,  -0.914],\n        [  2.61 ,   9.495,  -2.308],\n        [  1.174,  13.829,   0.201],\n        [  1.58 ,  20.115,   3.76 ],\n        [ -1.575,  16.928,   5.897],\n        [ -6.051,  14.762,   5.224],\n        [ -5.554,  10.415,   4.309],\n        [ -3.107,   6.405,   2.12 ],\n        [ -1.41 ,   3.335,  -2.655],\n        [  1.866,  -0.716,  -4.333],\n        [  3.655,  -4.444,  -2.485],\n        [  5.314,  -7.656,   1.13 ],\n        [  7.931,  -9.528,   5.781],\n        [  8.735, -12.648,  10.025],\n        [  9.108, -17.296,  13.021],\n        [  8.897, -22.606,  14.308],\n        [  9.673, -28.338,  13.292],\n        [ 12.641, -30.907,   9.645]], dtype=float32),\n 'masks': array([[ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True],\n        [ True,  True,  True]])}"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Create Dataset for CNN","metadata":{}},{"cell_type":"code","source":"def generate_dataset(seq, stacked_coords):\n    X, y, my, tids = [], [], [], []\n\n    for idx, row in seq.iterrows():  #遍历 DataFrame 的每一行，逐行处理\n        tid = row['target_id']\n        if tid in stacked_coords:      #sequence中的target_id 在 label.csv中存在的话\n            X.append(row['encoded_seq'])\n            y.append(stacked_coords[tid]['coords'])\n            my.append(stacked_coords[tid]['masks'])  #掩码列表\n            tids.append(tid)   # 用来跟踪样本来源\n\n    return X, y, my, tids\n\ntrain_X, train_y, train_my, train_tids = generate_dataset(train_sequence, train_stacked_coords)\nval_X, val_y, val_my, val_tids = generate_dataset(val_sequence, val_stacked_coords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:21.680678Z","iopub.execute_input":"2025-04-01T12:08:21.680973Z","iopub.status.idle":"2025-04-01T12:08:21.725031Z","shell.execute_reply.started":"2025-04-01T12:08:21.680947Z","shell.execute_reply":"2025-04-01T12:08:21.724364Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nfrom torch.nn.utils.rnn import pad_sequence #pad_sequence 函数的主要功能是对多个不同长度的序列进行填充（padding），使它们的长度达到一致，从而可以将这些序列组合成一个批量（batch）数据，方便输入到神经网络中进行处理。在自然语言处理、语音识别、RNA 序列分析等涉及序列数据的任务中，由于不同样本的序列长度往往不同，所以需要使用该函数进行长度统一。\n\ndef pad_sequences_torch(sequences, max_len, padding='post', value=0):  #post是在序列末尾填充pre是在前面填充（生物学上，末尾填充可以避免截断头部特征）\n    padded = pad_sequence([\n        torch.cat([seq, torch.full((max_len - len(seq),), value, dtype=seq.dtype)])  #torch.full()生成固定填充值的张量((x,)填充长度为x,填充值,dtype)\n        if len(seq) < max_len else seq[:max_len]\n        for seq in sequences\n    ], batch_first=True, padding_value=value)  # batch_first:指定张量的批量维度为第一维 默认是(seq_len, batch_size, features)。**batch_first=True**：(batch_size, seq_len, features)  这里就可以不用permute了\n    return padded\n\nmax_len = max(len(seq) for seq in train_X)\n\ntrain_X_pad = pad_sequences_torch([torch.tensor(x) for x in train_X], max_len)\nval_X_pad = pad_sequences_torch([torch.tensor(x) for x in val_X], max_len)\ntest_X = test_sequence['encoded_seq'].tolist()    #test还是Seires,需要转化成列表.\ntest_X_pad = pad_sequences_torch([torch.tensor(x) for x in test_sequence['encoded_seq'].tolist()], max_len)\n\ntrain_X_pad.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:27.562462Z","iopub.execute_input":"2025-04-01T12:08:27.562837Z","iopub.status.idle":"2025-04-01T12:08:30.764979Z","shell.execute_reply.started":"2025-04-01T12:08:27.562803Z","shell.execute_reply":"2025-04-01T12:08:30.764307Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"torch.Size([844, 4298])"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef pad_coords_torch(coords, max_len):\n    L = coords.size(0)\n    if L < max_len:\n        pad = (0, 0, 0, max_len - L)  # (left, right, top, bottom)\n        return F.pad(coords, pad, \"constant\", 0)        #pad()针对已有张量修改而full()是创建新张量    constant:使用固定值填充\n    else:\n        return coords[:max_len]\n\ntrain_y_pad = torch.stack([pad_coords_torch(torch.tensor(y), max_len) for y in train_y])\nval_y_pad = torch.stack([pad_coords_torch(torch.tensor(y), max_len) for y in val_y])\n\ntrain_my_pad = torch.stack([pad_coords_torch(torch.tensor(my), max_len) for my in train_my])\nval_my_pad = torch.stack([pad_coords_torch(torch.tensor(my), max_len) for my in val_my])\n\ntrain_y_pad.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:08:40.505445Z","iopub.execute_input":"2025-04-01T12:08:40.505880Z","iopub.status.idle":"2025-04-01T12:08:40.611825Z","shell.execute_reply.started":"2025-04-01T12:08:40.505853Z","shell.execute_reply":"2025-04-01T12:08:40.611041Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([844, 4298, 3])"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## CNN","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pytorch_lightning as pl           #PyTorch Lightning 是一个轻量级的 PyTorch 包装器，它通过提供高级的抽象和标准化的训练流程，帮助用户更高效地组织和训练 PyTorch 模型，减少了大量重复的样板代码\nfrom pytorch_lightning.callbacks import EarlyStopping\n\nclass CNN(pl.LightningModule):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Embedding layer    嵌入层的主要作用是将离散的整数索引映射为连续的向量表示。在自然语言处理、生物信息学等领域中，经常需要将离散的符号（如单词、碱基等）转换为连续的向量，以便于神经网络进行处理。\n        self.embedding = nn.Embedding(\n            num_embeddings=config['seq_mapping_size'],\n            embedding_dim=config['embedding_dim'],\n            padding_idx=0  #可选参数，用于指定填充位置的索引。当输入序列长度不一致时，通常会使用填充操作将序列填充到相同的长度，填充位置的索引可以通过 padding_idx 指定，填充位置对应的嵌入向量通常会被设置为全零向量\n        )\n        \n        # First Conv Block\n        self.conv1 = nn.Conv1d(\n            in_channels=config['embedding_dim'],\n            out_channels=config['num_filters'],\n            kernel_size=config['kernel_size'],\n            padding='same'  #保持序列长度不变\n        )\n        self.bn1 = nn.BatchNorm1d(config['num_filters'])\n        self.drop1 = nn.Dropout(config['drop_rate'])\n        \n        # Second Conv Block\n        self.conv2 = nn.Conv1d(\n            in_channels=config['num_filters'],\n            out_channels=config['num_filters'],\n            kernel_size=config['kernel_size'],\n            padding='same'\n        )\n        self.shortcut = nn.Conv1d(config['num_filters'], config['num_filters'], kernel_size=1)\n        \n        self.bn2 = nn.BatchNorm1d(config['num_filters']) #在深度神经网络的训练过程中，每一层的输入分布会随着前面层的参数更新而发生变化，这被称为内部协变量偏移（Internal Covariate Shift）。内部协变量偏移会使得后续层需要不断适应输入分布的变化，从而减慢模型的收敛速度。nn.BatchNorm1d 通过对每一批次的输入数据进行归一化处理，使得每一层的输入数据的均值接近 0，方差接近 1，从而减少了内部协变量偏移的影响。\n        self.drop2 = nn.Dropout(config['drop_rate'])\n        \n        \n        # Final Prediction Layer\n        self.final_conv = nn.Conv1d(\n            in_channels=config['num_filters'],\n            out_channels=3,  # x , y , z\n            kernel_size=1,    #为啥是1 ->不改变特征图尺寸1x1卷积核的空间感受野为1，在默认步长（stride=1）和填充（padding='same'）时，不会改变特征图的高度（H）和宽度（W），仅调整通道数（C）。应用场景：在RNA坐标预测任务中，需保持每个核苷酸残基的位置对齐（即序列长度L不变），确保输出坐标与输入序列一一对应\n            padding='same'\n        )\n        \n        self.loss_fn = nn.MSELoss(reduction='none')  #none:不进行任何聚合，直接返回每个位置（或元素）的独立损失值-适用与RNA预测  若是mean适用于回归任务 sum适用于回归任务的总误差计算；交叉熵损失中加权求和处理类别不平衡\n\n    def forward(self, x):\n        # Embedding\n        x = self.embedding(x)  # (batch, seq_len, embedding_dim)\n        x = x.permute(0, 2, 1)  # (batch, embedding_dim, seq_len)   - Conv1d要求输入张量格式为(batch, channels, sequence_length)  这个permute是torch.Tensor里面的方法\n        \n        # First Conv Block\n        x = F.silu(self.conv1(x))  #激活函数引入非线性  通道数变为num_filters\n        x = self.bn1(x)\n        x = self.drop1(x)\n        \n        # Second Conv Block\n        residual = self.shortcut(x)\n        x = F.silu(self.conv2(x)+residual)  # Swish = x * sigmoid(x)\n        x = self.bn2(x)\n        x = self.drop2(x)\n\n        # Final Prediction\n        x = self.final_conv(x)\n        x = x.permute(0, 2, 1)  # (batch, seq_len, 3)\n        return x\n    \n    def training_step(self, batch, batch_idx):\n        x, y, my = batch    #batch 包含数据 x、标签 y 和掩码 my\n        y_hat = self(x)  #也就是forawrd(x)\n        loss = self.loss_fn(y_hat, y)\n        loss = (my * loss).mean()   ##掩码过滤：通过逐元素乘法 my * loss 过滤无效位置（掩码值为 0 的位置损失归零）   生物学意义：在 RNA 结构预测中，掩码常用于忽略填充的无效核苷酸位置，确保模型仅优化有效区域的坐标\n\n        \n        self.log('train_loss', loss, prog_bar=True)  # 记录训练损失，prog_bar=True 显示在进度条\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y, my = batch\n        y_hat = self(x)\n        loss = self.loss_fn(y_hat, y)\n        loss = (my * loss).mean()  \n\n        self.log('val_loss', loss, prog_bar=True)  \n        return loss\n    \n    def configure_optimizers(self):\n        # return torch.optim.Adam(self.parameters())\n        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=0.01)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=2\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"},\n        }\n\n\nconfig = {\n    'seq_mapping_size': max(seq_dict.values()) + 1,\n    'embedding_dim': 16,\n    'num_filters':32,\n    'kernel_size': 3,\n    'drop_rate': 0.4,\n    'weight_decay': 0.0035,\n    'train_epochs': 550,\n    'batch_size': 16\n}\n\n\ntrain_dataset = TensorDataset(train_X_pad, train_y_pad, train_my_pad.long())\nval_dataset = TensorDataset(val_X_pad, val_y_pad, val_my_pad.long())\n\ntrain_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True,num_workers = 3)\nval_loader = DataLoader(val_dataset, batch_size=config['batch_size'],num_workers = 3)\n\n\nmodel = CNN(config)\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n\ntrainer = pl.Trainer(\n    max_epochs=config['train_epochs'],\n    callbacks=[early_stop],\n    accelerator='auto',\n    precision='16-mixed',  # 启用混合精度 -  自动切换FP16和FP32   - 技术原理前向传播：使用 FP16 计算，减少显存占用和计算时间。反向传播：仍用 FP16 计算梯度，但通过梯度缩放（Gradient Scaling）防止数值下溢。参数更新：最终参数用 FP32 存储，避免精度损失。\n    accumulate_grad_batches=4, #模拟更大batch size，提升训练稳定性.过累积实现等效batch_size=128\n    gradient_clip_val=0.5,  # 梯度裁剪 由于加了梯度累计需要加梯度裁剪防止梯度爆炸导致模型无法收敛\n    enable_progress_bar=True,\n    log_every_n_steps=1,\n)\ntrainer.fit(model, train_loader, val_loader)\n\n\n# 训练后保存模型\ntorch.save(model.state_dict(), \"rna_model.pth\")\n\n# 测试时重新加载\nmodel = CNN(config)\n# 安全加载：仅加载参数，忽略其他对象\nstate_dict = torch.load(\n    \"rna_model.pth\",\n    weights_only=True,  # 正确位置\n    map_location='cpu'  # 可选：指定设备\n)\nmodel.load_state_dict(state_dict)\n\n\ntest_tensor = torch.LongTensor(test_X_pad)\nmodel.eval()\nwith torch.no_grad():\n    pred = model(test_tensor).cpu().numpy()\n\nprint(pred.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T12:22:58.088571Z","iopub.execute_input":"2025-04-01T12:22:58.088910Z","iopub.status.idle":"2025-04-01T12:23:24.870347Z","shell.execute_reply.started":"2025-04-01T12:22:58.088874Z","shell.execute_reply":"2025-04-01T12:23:24.869332Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d4b2cee4ef4806b7fe92c7dd1d271c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"(12, 4298, 3)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Submission\n- the target 3 dimensional coordinates are duplicated 5 times","metadata":{}},{"cell_type":"code","source":"rows = []\n\nfor idx, row in test_sequence.iterrows():\n    target_id = row['target_id']\n    coords = pred[idx]\n    seq_length = len(row['encoded_seq'])\n    coords = coords[:seq_length, :]\n\n    for i in range(seq_length):\n        x, y, z = coords[i, :]\n        rows.append(\n            {\n                'ID': f\"{target_id}_{i+1}\",\n                'resname': row['sequence'][i],\n                'resid': i+1,\n                 **{f\"x_{j+1}\": x for j in range(5)},\n                 **{f\"y_{j+1}\": y for j in range(5)},\n                 **{f\"z_{j+1}\": z for j in range(5)}\n            }\n        )\n\nsubmission = pd.DataFrame(rows)\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:42:44.238104Z","iopub.execute_input":"2025-04-01T07:42:44.238571Z","iopub.status.idle":"2025-04-01T07:42:44.338553Z","shell.execute_reply.started":"2025-04-01T07:42:44.238535Z","shell.execute_reply":"2025-04-01T07:42:44.337838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}